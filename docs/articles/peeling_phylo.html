<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Peeling Algorithm in Phylogenic Trees • aphylo</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Peeling Algorithm in Phylogenic Trees">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">aphylo</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.0.99</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/data_imputation.html">Untitled</a>
    </li>
    <li>
      <a href="../articles/peeling_phylo.html">Peeling Algorithm in Phylogenic Trees</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/USCbiostats/phylogenetic">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Peeling Algorithm in Phylogenic Trees</h1>
            
            <h4 class="date">This version 2018-08-30</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/USCbiostats/phylogenetic/blob/master/vignettes/peeling_phylo.rmd"><code>vignettes/peeling_phylo.rmd</code></a></small>
      <div class="hidden name"><code>peeling_phylo.rmd</code></div>

    </div>

    
    
<div id="definitions" class="section level1">
<h1 class="hasAnchor">
<a href="#definitions" class="anchor"></a>Definitions</h1>
<div id="anotated-phylogenetic-trees" class="section level2">
<h2 class="hasAnchor">
<a href="#anotated-phylogenetic-trees" class="anchor"></a>Anotated Phylogenetic Trees</h2>
<p>A phylogenetic tree <span class="math inline">\(\tau\equiv (N,E)\)</span> is a tuple of nodes <span class="math inline">\(N\)</span>, and edges <span class="math inline">\(E\equiv \{(n, m) \in N\times N: n\mapsto m\}\)</span> defined by the binary operator <span class="math inline">\(\mapsto\)</span> <em>parent of</em>. Furthermore, we define <span class="math inline">\(O(n)\equiv\{m\in N: (n, m) \in E\}\)</span> as the set of offspring of <span class="math inline">\(n\)</span>, and <span class="math inline">\(r(m) \equiv\{n \in N: (n, m) \in E\}\)</span> the parent nodes of <span class="math inline">\(m\)</span>. For now on we assume that <span class="math inline">\(|r(m)| \leq 1,\forall n\in N\)</span>.</p>
<p>Given <span class="math inline">\(P\)</span> gene functions, let <span class="math inline">\(A \equiv \{a_n \in \{0,1\}^P: n\in N\}\)</span> denote a set of genetic annotations–which we will also refer as states–of the genes <span class="math inline">\(N\)</span>. We define an Annotated Phylogenetic Tree as the tuple <span class="math inline">\(D \equiv(\tau, A)\)</span>. Furthermore, we say that this structure is a Partially Ordered Annotated Phylogenetic Tree if it’s nodes labels form a partial order, this is <span class="math inline">\(E\equiv \{(n, m) \in N\times N: n &lt; m\}\)</span>.</p>
<p>While <span class="math inline">\(A\)</span> exists, we only observe an imperfect approximation of it, experimental data <span class="math inline">\(\tilde A = \{\tilde a_l\}_{l\in N}\)</span>, which only holds information for some of the leaf nodes. Therefore, for any given leaf node <span class="math inline">\(l\)</span>, the elements of <span class="math inline">\(\{\tilde a_{lp}\}_{p=1}^P\)</span> can take the following values:</p>
<p><span class="math display">\[
\tilde a_{lp} = \left\{
\begin{array}{ll}
1 &amp; \mbox{if the function }p\mbox{ is cosidered as active}\\
0 &amp; \mbox{if the function }p\mbox{ is cosidered as non-active}\\
9 &amp; \mbox{if we don't have information }
\end{array}\right.
\]</span></p>
<p>This way, assuming that we observe the true phylogenetic tree, we denote the tuple <span class="math inline">\(\tilde D\equiv(\tau, \tilde A)\)</span> to be a Experimentally Annotated Phylogenetic Tree. Ultimately, we are interested in predicting functional annotations for the leaf nodes that have not been annotated yet.</p>
</div>
<div id="likelihood-of-an-anotated-phylogenetic-tree" class="section level2">
<h2 class="hasAnchor">
<a href="#likelihood-of-an-anotated-phylogenetic-tree" class="anchor"></a>Likelihood of an Anotated Phylogenetic Tree</h2>
<p>Given <span class="math inline">\(\tilde D\)</span>, the probability that the true state is of the <span class="math inline">\(l\)</span>-leaf is <span class="math inline">\(a_l = \{a_{lp}\}_{p=1}^P\)</span> is:</p>
<p><span class="math display">\[ 
\label{eq:1a}\tag{1a}
{{\mbox{Pr}\left(a_l\;|\;\tilde D, \psi\right) }} = \prod_{p = 1}^P\left\{\left[\psi_0^{\tilde a_{lp}}(1-\psi_0)^{1- \tilde a_{lp}}\right]^{1- a_{lp}} \left[\psi_1^{1- \tilde a_{lp}}(1-\psi_1)^{\tilde a_{lp}}\right]^{a_{lp}} \right\}^{\left[1 - {{\boldsymbol{1}\left\{ \tilde a_{lp} !=9 \right\}}}\right]}
\]</span></p>
<p>Where <span class="math inline">\(\psi\equiv\{\psi_0, \psi_1\}\)</span> is a vector of missclassification probabilities, formally:</p>
<p><span class="math display">\[
\psi_0 = {{\mbox{Pr}\left(\tilde a_{lp}=1\;|\;a_{lp} = 0\right) }},\quad
\psi_1 = {{\mbox{Pr}\left(\tilde a_{lp}=0\;|\;a_{lp} = 1\right) }}
\]</span></p>
<p>Computationally, observe that the largest parenthesis needs to be calculated only once and then retrieved depending on the values of <span class="math inline">\((a_{lp},\tilde a_{lp})\)</span>. Let <span class="math inline">\(S\)</span> be a square matrix defined as follows</p>
<p><span class="math display">\[
S = \left[\begin{array}{cc}
s_{00} &amp; s_{01} \\
s_{10} &amp; s_{11}
\end{array}\right]
=\left[\begin{array}{cc}
1-\psi_0 &amp; \psi_0 \\
\psi_1 &amp; 1 - \psi_1
\end{array}\right]
\]</span></p>
<p>Then, (1a) can be reexpress using <span class="math inline">\(S\)</span>:</p>
<p><span class="math display">\[ 
\label{eq:1b}\tag{1b}
{{\mbox{Pr}\left(a_l\;|\;\tilde D, \psi\right) }} = \prod_{p = 1}^P {s_{a_{lp} \tilde a_{lp}}}^{\left[1 - {{\boldsymbol{1}\left\{ \tilde a_{lp} !=9 \right\}}}\right]}
\]</span></p>
<p>For any internal node <span class="math inline">\(n \in N\)</span>, the probability of observing a given state is defined in terms of its offspring <span class="math inline">\(O(n)\)</span>, and parameters <span class="math inline">\((\psi, \mu)\)</span>, where <span class="math inline">\(\mu \equiv \{\mu_0,\mu_1\}\)</span> is a vector of probabilities of gain and loss of a function, formally</p>
<p><span class="math display">\[
\mu_0 = {{\mbox{Pr}\left(a_{lp} = 1\;|\;a_{r(l)p} = 0\right) }},\quad  \mu_0 = {{\mbox{Pr}\left(a_{lp} = 0\;|\;a_{r(l)p} = 1\right) }}
\]</span></p>
<p>This way, the probability of observing state <span class="math inline">\(a_n = \{a_{np}\}_{p=1}^P\)</span> is</p>
<p><span class="math display">\[
\tag{2}
{{\mbox{Pr}\left(a_n\;|\;\tilde D, \psi,\mu\right) }} = \prod_{m \in O_n} \sum_{a_m \in \{0,1\}^P} {{\mbox{Pr}\left(a_m\;|\;\tilde D, \psi,\mu\right) }}
\prod_{p = 1}^P \left\{\left[\mu_0^{a_{mp}}(1-\mu_0)^{1 - a_{mp}}\right]^{1 - a_{np}}
  \left[\mu_1^{1 - a_{mp}}(1-\mu_1)^{a_{mp}}\right]^{a_{np}}\right\}
\]</span></p>
<p>Observe that if <span class="math inline">\(m\in O(n)\)</span> is a leaf node, then <span class="math inline">\({{\mbox{Pr}\left(a_m\;|\;\tilde D, \psi,\mu\right) }} = {{\mbox{Pr}\left(a_m\;|\;\tilde D, \psi\right) }}\)</span> which was defined in (1b).</p>
<p>Let <span class="math inline">\(M\equiv\{m_{ij}\}_{i,j \in \{0,1\}}\)</span> to be an array of size <span class="math inline">\(2\times 2\)</span> holding the Gain/Loss probabilities, formally</p>
<p><span class="math display">\[
M = \left[\begin{array}{cc}
m_{00} &amp; m_{01} \\
m_{10} &amp; m_{11}
\end{array}\right]
= \left[\begin{array}{cc}
1-\mu_0 &amp; \mu_0 \\
\mu_1 &amp; 1 - \mu_1
\end{array}\right]
\]</span></p>
<p>This way, (2a) can be reexpress as follows</p>
<p><span class="math display">\[
\tag{2b}
{{\mbox{Pr}\left(a_n\;|\;\tilde D, \psi,\mu\right) }} = \prod_{m \in O_n} \sum_{a_m \in \{0,1\}^P} {{\mbox{Pr}\left(a_m\;|\;\tilde D, \psi,\mu\right) }}
\prod_p m_{a_{np}a_{mp}}
\]</span></p>
<p>Finally, let <span class="math inline">\(\pi\equiv\{\pi_p\}_{p=1}^{P}\)</span> to be the root node state probabilities for each function, then, the likelihood of observing a particular set of annotations conditional on the tree structure and model parameters can be computed using the root node states probabilities:</p>
<p><span class="math display">\[
\tag{3}
{{\mbox{Pr}\left(\tilde A\;|\;\tau,\psi, \mu, \pi\right) }} = \sum_{a_0 \in \{0,1\}^P} {{\mbox{Pr}\left(a_0\;|\;\pi\right) }} {{\mbox{Pr}\left(a_0\;|\;\tilde D,\psi,\mu\right) }}
\]</span></p>
<p>where <span class="math inline">\({{\mbox{Pr}\left(a_0\;|\;\pi\right) }} = \prod_{p=1}^P \pi_p^{a_{0p}}\left(1 - \pi_p\right)^{1 - a_{0p}}\)</span>.</p>
</div>
</div>
<div id="estimation" class="section level1">
<h1 class="hasAnchor">
<a href="#estimation" class="anchor"></a>Estimation</h1>
<div id="maximum-likelihood" class="section level2">
<h2 class="hasAnchor">
<a href="#maximum-likelihood" class="anchor"></a>Maximum Likelihood</h2>
<p>Let <span class="math inline">\(\theta = (\psi, \mu, \pi)\)</span> denote the vector of model parameters. Furthermore, <span class="math inline">\(\theta \in \Psi\times \mathcal{M} \times \Pi\)</span>, then, the maximun likelihood estimator <span class="math inline">\(\hat \theta\)</span> is</p>
<p><span class="math display">\[
(\hat \psi, \hat \mu, \hat \pi) = \hat\theta = \arg \max_{\theta \in \Theta} \log {{\mbox{Pr}\left(\tilde A\;|\;\tau, \theta\right) }}
\]</span></p>
</div>
<div id="markov-chain-monte-carlo-with-reflective-boundaries-kernel" class="section level2">
<h2 class="hasAnchor">
<a href="#markov-chain-monte-carlo-with-reflective-boundaries-kernel" class="anchor"></a>Markov Chain Monte Carlo with Reflective Boundaries Kernel</h2>
</div>
</div>
<div id="assesment-of-model-predictions" class="section level1">
<h1 class="hasAnchor">
<a href="#assesment-of-model-predictions" class="anchor"></a>Assesment of Model Predictions</h1>
<p>Let <span class="math inline">\(A_H\)</span> and <span class="math inline">\(\hat A_H\)</span> be the observed and predicted annotations for the set of nodes <span class="math inline">\(H\)</span>. We write <span class="math inline">\(W_H\)</span> to refer to the undirected shortest path length matrix in which each one of its entries <span class="math inline">\(w_{Hnm}\)</span> holds shortest path length between nodes <span class="math inline">\(n, m\)</span> <span class="math inline">\(\in H\)</span>. Then, we assess the prediction quality by the following statistic</p>
<p><span class="math display">\[
\left\{\left\| a_h - \hat a_h \right\|\right\}_{h \in H}^\mathbf{t}
\left(W_H + I_{|H|}\right)^{-1}
\left\{\left\| a_h - \hat a_h \right\|\right\}_{h \in H}
\]</span></p>
<p>Where <span class="math inline">\(I_{|H|}\)</span> is the identity matrix of size <span class="math inline">\(|H|^2\)</span>, and <span class="math inline">\(\|\cdot\|\)</span> is the <span class="math inline">\(\ell^2\)</span>-norm.</p>
<p>It can be shown that the previous expression can be written as</p>
<p><span class="math display">\[
\delta = \sum_{i,j}\left[\sum_{p,r} (a_{ip} - \hat a_{ir})^2(a_{jr} - \hat a_{jr})^2\right]^{1/2}w_{ij}^{-1}
\]</span></p>
<p>So, <span class="math inline">\(\mbox{E}\left(\delta\right)\)</span> reduces to computing the following</p>
<p><span class="math display">\[
\sum_{i,j} w_{ij}^{-1}\mbox{E}\left[\sum_{p,r} (a_{ip} - \hat a_{ir})^2(a_{jr} - \hat a_{jr})^2\right]^{1/2}
\]</span></p>
</div>
<div id="data-imputation" class="section level1">
<h1 class="hasAnchor">
<a href="#data-imputation" class="anchor"></a>Data Imputation</h1>
<p>The ultimate goal of this model is to be able to predict, or rather, impute functional states to leaf nodes for which we do not have information. Using both, the information that we have about the annotated tree and the parameter estimates of gain and loss probabilities, we can calculate what is the probability of observing either a 0 or a 1. Formally, with <span class="math inline">\(S\equiv (N, E)\)</span>, the probability of leaf node <span class="math inline">\(n\)</span> having state <span class="math inline">\(a_l = \{a_{lp}\}_{p=1}^P\)</span>, conditional on the tree structure <span class="math inline">\(\tilde D S^*\)</span> and the observed set of annotations <span class="math inline">\(A^*\)</span> is:</p>
<p><span class="math display">\[
\tag{1}
{{\mbox{Pr}\left(a_{np} = 1\;|\;\tau, \tilde A\right) }} = \frac{{{\mbox{Pr}\left(\tilde A\;|\;\tau, a_{np} = 1\right) }} {{\mbox{Pr}\left(a_{np}=1\;|\;\tau\right) }}}{
{{\mbox{Pr}\left(\tilde A\;|\;\tau\right) }}
}
\]</span></p>
<p>For ease of notation, we will drop the <span class="math inline">\(\tau\)</span>, as all probabilities throughout this section are conditional on the tree structure. Now, we know that</p>
<p><span class="math display">\[
\tag{2}\label{eq:2}
{{\mbox{Pr}\left(\tilde A\right) }} = {{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 1\right) }} {{\mbox{Pr}\left(a_{np} = 1\right) }} + {{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 0\right) }} (1 - {{\mbox{Pr}\left(a_{np} = 1\right) }})
\]</span></p>
<p>Hence, pluging in (2) into (1), and multiplying both numerator and denominator by <span class="math inline">\(1/{{\mbox{Pr}\left(a_{np} = 1\right) }}\)</span>, (1) can be rewritten as</p>
<p><span class="math display">\[
\tag{1'}
{{\mbox{Pr}\left(a_{np} = 1\;|\;\tilde A\right) }} = \frac{{{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 1\right) }}}{
{{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 1\right) }} + {{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 0\right) }} \frac{\left(1 - {{\mbox{Pr}\left(a_{np} = 1\right) }}\right)}{{{\mbox{Pr}\left(a_{np} = 1\right) }}}
}
\]</span> Where <span class="math inline">\({{\mbox{Pr}\left(\tilde A\;|\;a_{np} = 1\right) }}\)</span> is the likelihood of the data given that we set the ith node to be 1, which we already know how to compute. This way, we are only missing <span class="math inline">\({{\mbox{Pr}\left(a_{np=1}\right) }}\)</span>, which we can compute as follows:</p>
<p><span class="math display">\[
\begin{align}
{{\mbox{Pr}\left(a_{np} = 1\right) }} &amp; = \pi_p {{\mbox{Pr}\left(a_{np} = 1\;|\;a_{0p} = 1\right) }} + (1 - \pi_p) {{\mbox{Pr}\left(a_{np} = 1\;|\;a_{0p} = 0\right) }}
\end{align}
\]</span></p>
<p>Where, given that <span class="math inline">\(\gamma_{01}\)</span> is the shorest path length between node 0 and node <span class="math inline">\(i\)</span>, we have:</p>
<p><span class="math display">\[
\left[\begin{array}{cc}
{{\mbox{Pr}\left(a_i = 0\;|\;a_0 = 0\right) }} &amp; {{\mbox{Pr}\left(a_i = 1\;|\;a_0 = 0\right) }} \\
{{\mbox{Pr}\left(a_i = 0\;|\;a_0 = 1\right) }} &amp; {{\mbox{Pr}\left(a_i = 1\;|\;a_0 = 1\right) }}
\end{array}
\right]
=
\left[\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array} \right] \times
\left[\begin{array}{cc}
1 - \hat\mu_0 &amp;  \hat\mu_0 \\
\hat\mu_1 &amp;  1 - \hat\mu_1
\end{array}
\right]^{\gamma_{0i}}
\]</span></p>
</div>
<div id="data" class="section level1">
<h1 class="hasAnchor">
<a href="#data" class="anchor"></a>Data</h1>
<p>The model uses two different datasets: (1) experimental data, which holds functions indicators, and (2) phylogenetic tree data, which contains the parent/offspring relations.</p>
<p>Given how the algorithm for computing the likelihood has been programmed, it is necessary that the experimental dataset must have as many rows as nodes (parents and offspring) there are. To fulfill such requirement, the package <code>phylogenetic</code>, throught the function <code>prepare_data</code>, ``completes’’ the experimental dataset as follows:</p>
<ol style="list-style-type: decimal">
<li><p>List all nodes in the tree that are not in the experimental dataset.</p></li>
<li><p>Once identified, if any, add those nodes to the experimental dataset. The function indicator columns will have value ‘9’ (unknown). Furthermore, the added nodes are tagged so that the user can identify them later.</p></li>
<li><p>The new experimental dataset is sorted increasingly according to the node id number. The idea is that the root, node 0, should appear in the first row.</p></li>
</ol>
<p>Once the experimental data has been processed,</p>
<ol start="4" style="list-style-type: decimal">
<li>We identify</li>
</ol>
</div>
<div id="maximum-a-posteriori-map-estimation" class="section level1">
<h1 class="hasAnchor">
<a href="#maximum-a-posteriori-map-estimation" class="anchor"></a>Maximum a Posteriori (MAP) Estimation</h1>
<p>Using bayes we have</p>
<p><span class="math display">\[
{{f\left(\theta\;|\;D\right) }} = \frac{{{f\left(X\;|\;\theta\right) }}{{f\left(\theta\right) }}}{f{X}}
\]</span></p>
<p>Then, assumming iid, to estimate <span class="math inline">\(\hat \theta\)</span> we can solve the following problem</p>
<p><span class="math display">\[
\label{eq:maptheta}
\begin{align}
\hat \theta &amp; = \arg\max_{\theta \in \Theta} \frac{{{f\left(X\;|\;\theta\right) }}{{f\left(\theta\right) }}}{{{f\left(X\right) }}} \\
 &amp; \mbox{Since the denominator is constant, this is equivalent to} \\
 &amp; = \arg\max_{\theta \in \Theta} {{f\left(X\;|\;\theta\right) }}{{f\left(\theta\right) }} \tag{MAP estimate} 
\end{align}
\]</span></p>
<p>Observe that under a uniform prior, this is equivalent to the MLE estimate. Now, the variance (what about the covariance) estimator is as follows</p>
<p><span class="math display">\[
\label{eq:mapvar}
\mbox{Var}\left(\hat\theta\right) = \int_{\theta \in \Theta} \left(\hat\theta - \theta\right)^2
\frac{{{f\left(X\;|\;\theta\right) }}{{f\left(\theta\right) }}}{{{f\left(X\right) }}} d\theta \tag{MAP variance}
\]</span></p>
<p>Where the denominator, probability of evidence, can be computed as</p>
<p><span class="math display">\[
\label{eq:d}
{{f\left(X\right) }} = \int_{\theta \in \Theta} {{f\left(X\;|\;\theta\right) }}{{f\left(\theta\right) }}d\theta 
\]</span></p>
<p>Given <span class="math inline">\(\hat \theta\)</span>, the variance can be computed using numerical integration.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#definitions">Definitions</a><ul class="nav nav-pills nav-stacked">
<li><a href="#anotated-phylogenetic-trees">Anotated Phylogenetic Trees</a></li>
      <li><a href="#likelihood-of-an-anotated-phylogenetic-tree">Likelihood of an Anotated Phylogenetic Tree</a></li>
      </ul>
</li>
      <li>
<a href="#estimation">Estimation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#maximum-likelihood">Maximum Likelihood</a></li>
      <li><a href="#markov-chain-monte-carlo-with-reflective-boundaries-kernel">Markov Chain Monte Carlo with Reflective Boundaries Kernel</a></li>
      </ul>
</li>
      <li><a href="#assesment-of-model-predictions">Assesment of Model Predictions</a></li>
      <li><a href="#data-imputation">Data Imputation</a></li>
      <li><a href="#data">Data</a></li>
      <li><a href="#maximum-a-posteriori-map-estimation">Maximum a Posteriori (MAP) Estimation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by George Vega Yon.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
