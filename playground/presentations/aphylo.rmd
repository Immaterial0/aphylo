---
title: "Project 2: Augmenting functional information about human genes using probabilistic phylogenetic modeling"
short_title: 
author: "George G. Vega Yon"
date: "October 5, 2017"
institute:
  - Department of Preventive Medicine
  - University of Southern California
short_institute: USC
short_author: Vega Yon
output: 
  uscimage::beamer_USCImage:
    includes:
      in_header:
        aphylo.sty
    toc: false
    highlight: zenburn
section-titles: false
fontsize: 9pt
handout: true
page-number: true
---


```{r setup, include=FALSE}
knitr::knit_hooks$set(smallsize = function(before, options, envir) {
    if (before) {
        "\\footnotesize\n\n"
    } else {
        "\n\\normalsize\n\n"
    }
})

knitr::opts_chunk$set(echo = FALSE, smallsize=TRUE,
                      out.width = ".8\\linewidth",
                      fig.width = 7, fig.height = 5, fig.align = 'center')

library(aphylo)
```

## Agenda

\tableofcontents{}

# Gene Functions

## Agenda

\tableofcontents[currentsection]

## Introduction

-   Manual Curation (GO): Good but infeasible \pause
-   Sparse gene functional annotation \pause
-   Take advantage of the phylogenetic information to make inference of  \pause
-   This predicted functional information will
serve as prior covariates (and prior gene-gene connections) in the second level of the hierarchical models in Projects 1 and 3. In particular, this project is the first to make predictions at large scale in a probabilistic
manner.

# Model

## Agenda

\tableofcontents[currentsection]

## Some definitions

1.  Phylogenetic tree: In our case, we talk about \textcolor{red}{partially ordered} phylogenetic tree, in particular, $\phylo\equiv (N,E)$ is a tuple of nodes $N$, and edges

    $$
    E\equiv \{(n, m) \in N\times N: n\mapsto m, \textcolor{red}{n < m}\}
    $$

2.  Offspring of $n$: $O(n)\equiv\{m\in N: (n, m) \in E, n\in N\}$

3.  Parent node of $m$: $r(m) \equiv\{n \in N: (n, m) \in E, m\in N\}$

4.  Leaf nodes: $\Leaf(\phylo)\equiv \{m \in N: O(m)=\{\emptyset\}\}$

5.  Annotations: Given $P$ functions, $\Ann \equiv \{\ann_n \in \{0,1\}^P: n\in \Leaf(\phylo)\}$

6.  Annotated Phylogenetic Tree $\aphylo \equiv(\phylo, \Ann)$

## Some definitions (cont. 1)

7.  Observed Annotated Annotations $\AnnObs = \{\annObs_l\}_{l\in \Leaf(\phylo)}$, where

$$
\annObs_{lp} = \left\{
\begin{array}{ll}
1 & \mbox{if the function }p\mbox{ is believed to be present}\\
0 & \mbox{if the function }p\mbox{ is believed to be absent}\\
9 & \mbox{if we don't have information for this node }
\end{array}\right.
$$

8.  Experimentally Annotated Phylogenetic Tree $\aphyloObs\equiv(\phylo, \AnnObs)$

## A probabilistic model of function propagation

1.  For any given node, we can write down the probability of observing a \emph{functional state} as a function of some model parameters and its offspring. \pause
    
2.  This version of our model has five parameters (probabilities): \pause
    
    a.  Root node had a function: $\pi$, 
    b.  Gain of function: $\mu_0$,
    c.  Loss of function: $\mu_1$.
    d.  Misclassification of:
        -   A missing function as present, $\psi_0$, and
        -   A present function as missing, $\psi_1$ \pause

    All five parameters are assumed to be equal across functions, this is, $\pi, \mu_0, \mu_1, \psi_0$, and $\psi_1$ are assumed to be independent of the functions that are analyzed.\pause
    
3.  In this presentation, we will focus on the case that $P = 1$.


## Leaf node probabilities {.t}

-   The probability of the leaf nodes having annotations $\annObs_l$ conditional on the actual annotation is \pause
    
    \begin{equation}
    \label{eq:leaf1}
    \Prcond{\AnnObs_{l} = \annObs_{l}}{\Ann_{l} = \ann_{l}} = \left\{
    \begin{array}{ll}
    \psi &\mbox{if }\annObs_{l} \neq \ann_{l} \\
    1 - \psi & \mbox{otherwise}
    \end{array}
    \right.
    \end{equation}
    
    Where $\psi$ can be either $\psi_0$ (mislabelling a zero), or $\psi_1$ (mislabelling a one).
    

## Internal node probabilities {.t}

-   In the case of the internal nodes, the probability of a given state is defined in terms of the gain/loss probabilities \pause
    
    $$
    \Prcond{\Ann_{n} = \ann_{lp}}{\Ann_{r(n)} = \ann_{r(n)}} = \left\{
    \begin{array}{ll}
    \mu & \mbox{if }\ann_{n} \neq \ann_{r(n)} \\
    1 - \mu & \mbox{otherwise}
    \end{array}
    \right.
    $$
    
    Where $\mu$ can be either $\mu_0$ (gain), or $\mu_1$ (loss). \pause
    
-   Assuming independence accross offspring, we can write \pause
    
    
    \begin{multline}
    \label{eq:interior1}
    \Prcond{\Ann_n = \ann_n}{\aphyloObs} = %
    \prod_{m \in O(n)} \sum_{\ann_m \in \{0,1\}} \Prcond{\Ann_m = \ann_m}{\aphyloObs} \\
    \Prcond{\Ann_{m} = \ann_{m}}{\Ann_{n} = \ann_{n}}
    \end{multline} \pause
    
    Notice that if $m$ is a leaf node, then $\Prcond{\Ann_m = \ann_m}{\aphyloObs} = \Prcond{\AnnObs_m = \annObs_m}{\Ann_m = \ann_m}$.

## Likelihood of the tree {.t}

-   Once the computation reaches the root node, $n=0$, equations \eqref{eq:leaf1} and \eqref{eq:interior1}: \pause
    
    \tiny
    
    \begin{align*}
    \Prcond{\Ann_l = \ann_l}{\aphyloObs} & = \Prcond{\Ann_{l} = \ann_{lp}}{\AnnObs_{l} = \annObs_{l}} \tag{\ref{eq:leaf1}}\\
    \Prcond{\Ann_n = \ann_n}{\aphyloObs}  & = 
    \prod_{m \in O(n)} \sum_{\ann_m \in \{0,1\}} \Prcond{\Ann_m = \ann_m}{\aphyloObs}  
    \Prcond{\Ann_{m} = \ann_{mp}}{\Ann_{n} = \ann_{n}} \tag{\ref{eq:interior1}}
    \end{align*}
    
    
    \normalsize
    
    Allow us writing the likelihood of the entire tree
    
    \begin{equation}
    \label{eq:l}
    \likelihood{\psi, \mu, \pi}{\aphyloObs} = \sum_{\ann_0\in\{0,1\}}\Prcond{\Ann_0=\ann_0}{\pi}\Prcond{\Ann_0=\ann_0}{\aphyloObs}
    \end{equation}
    
    Where $\Prcond{\Ann_0=\ann_0}{\pi} = \pi^{\ann_{0}}\left(1 - \pi\right)^{1 - \ann_{0}}$

## Peeling algorithm {.t}

Given an Experimentally Annotated (PO) Phylogenetic Tree, the likelihood computation on a single function is as follows.

1.  Create an matrix $A$ of size $2 \times |N|$,

2.  For node $n = \{|N|, |N| - 1, \dots, 1, 0\}$ do:
    
    a.  For $\ann_n\in \{0,1\}$ do:
        
        a.  Set $A_{n, \ann_n} = \left\{\begin{array}{ll}
        \Prcond{\AnnObs_n = \annObs_n}{\Ann_n = \AnnObs_n} & \mbox{If }$n$\mbox{ is a leaf} \\
        \Prcond{\Ann_n = \ann_n}{\aphyloObs_n} & \mbox{otherwise}
        \end{array}
        \right.$
        
        b.  Next $\ann_n$
    
    b.  Next $n$
    
3.  At this point the matrix $A$ should be completely filled, so following \eqref{eq:l}, we can compute
    
    $$
    \likelihood{\psi, \mu, \pi}{\aphyloObs} = \sum_{\ann_0\in\{0,1\}}\Prcond{\Ann_0=\ann_0}{\pi}A_{0,\ann_0}
    $$


## Prediction



-   We implemented this in the `aphylo` R package...


# The `aphylo` R package

## Agenda

\tableofcontents[currentsection]

## `aphylo` in a nutshell

With `C++` (`RcppArmadillo`) under-the-hood, `aphylo`:

1.  Defines an S3 class for representing partially ordered trees, including validation of it.

2.  Includes from the basic methods: `print`, `plot`, and `summary`; to more advanced such as `prune`.

3.  Defines an S3 class for representing _annotated_ partially ordered trees.

4.  Includes functions for converting from and to `phylo` class objects from the `ape` package (most used/cited package in Phylogenetics in R)

5.  Implements the loglikelihood calculation of our model.

We'll talk about estimation later...

## Examples: Simulating Trees {.t}

\begincols

\begincol{.48\textwidth}

```{r example_sim_tree, echo=TRUE}
set.seed(80)
tree <- sim_tree(5)
tree
```

\endcol

\begincol{.48\textwidth}

```{r example_sim_ann_tree, echo=TRUE}
atree <- sim_annotated_tree(
  tree = tree, P = 2, Pi=.01, mu=c(.2, .1))
atree
```

\endcol

\endcols


## Examples: Visualizing annotated data {.c}

\begincols

\begincol{.49\textwidth}

```{r annotated-viz, echo=TRUE, message=FALSE, warning=FALSE, out.width="1\\linewidth", fig.cap="Visualization of annotations and tree structure.", cache=TRUE}
plot(atree)
```

\endcol

\begincol{.49\textwidth}

```{r likelihood-viz, echo=TRUE, message=FALSE, warning=FALSE, out.width="1\\linewidth", fig.cap="LogLikelihood surface of the simulated data"}
plot_LogLike(atree)
```

\endcol

\endcols

## Example: Interaction with ape {.t}

```{r as-apephylo, echo=TRUE}
as.apephylo(atree)
# we can go back using:
# as.po_tree(as.apephylo(atree))
```

## Example: Interaction with ape (cont.) {.t}

```{r plotting-ape, fig.cap="These should be identical. as conversion between classes preserves all the information.", cache=TRUE}
oldpar <- par(no.readonly = TRUE)
par(mfrow = c(1,2), mar=c(0,0,3,0))
plot(atree$edges, main = "PO tree")
plot(as.apephylo(atree), main = "APE tree")
par(oldpar)
```

## Example: Tree pruning {.t}

```{r tree-pruning1, fig.cap="Pruning trees"}
set.seed(1213)
x <- sim_tree(4)

# Setting up the plot envir
oldpar <- par(no.readonly = TRUE)
par(mfrow = c(2,3), mar=c(.5,0,2,0), cex=1, xpd=NA, omi=c(0,0,0,0))
# Plotting 
plot(x, main = "x", show.node.label = TRUE)
plot(prune(x, c(2,6)), main="prune(x, c(2,6))", show.node.label = TRUE)
plot(z<-prune(x, 6), main="prune(x, 6)", show.node.label = TRUE)
plot(prune(x, 4), main="prune(x, 4)", show.node.label = TRUE)
plot(prune(x, 3), main="prune(x, 3)", show.node.label = TRUE)
plot(prune(x, c(4,6,3)), main="prune(x, c(4,6,3))", show.node.label = TRUE)
par(oldpar)

```


## Example: Tree pruning (cont.) {.t}


```{r tree-pruning2, fig.cap="Pruning trees recursively"}
set.seed(1)
x <- sim_tree(25)
oldpar <- par(no.readonly=TRUE)
par(mfrow=c(2,2), cex=.75, xpd=NA, mar=c(1,0,2,0))
plot(x, main="x")
plot(prune(x, "leafs"), main = "prune(x, \"leafs\")")
plot(prune(prune(x, "leafs"), "leafs"), main = "prune(prune(x, \"leafs\"), \"leafs\")")
plot(prune(prune(prune(x, "leafs"), "leafs"), "leafs"), main = "prune(prune(prune(x, \"leafs\"), \"leafs\"), \"leafs\")")
par(oldpar)

```

# The `amcmc` R package

## Agenda

\tableofcontents[currentsection]

## Yet another MCMC package

You may be wondering why, well:

1.  Implements reflective boundaries random-walk kernel

2.  Allows running multiple chains simultaneously (parallel)

3.  Overall faster than other Metrop MCMC algorithms (from our experience)

4.  Planning to include other types of kernels (the Handbook of MCMC)

## Example: MCMC {.t}

```{r amcmc-data, echo=FALSE}
# Parameters
set.seed(1231)
n <- 1e3
pars <- c(mean = 2.6, sd = 3)

# Generating data and writing the log likelihood function
D <- rnorm(n, pars[1], pars[2])
```


```{r amcm-example, echo=TRUE, cache=TRUE}
# Loading the packages
library(amcmc)
library(coda)

# Defining the ll function (data was already defined)
ll <- function(x, D) {
  x <- log(dnorm(D, x[1], x[2]))
  sum(x)
}

ans <- MCMC(
  # Ll function and the starting parameters
  ll, c(mu=1, sigma=1),
  # How many steps, thinning, and burn-in
  nbatch = 1e5, thin=10, burnin = 100,
  # Kernel parameters
  scale = .1, ub = 10, lb = c(-10, 0),
  # How many parallel chains
  nchains = 4,
  # Further arguments passed to ll
  D=D
  )

```

## Example: MCMC (cont. 1) {.t}

`ans` is of class `mcmc` from the coda package

```{r amcmc-summary, echo=TRUE}
summary(ans)
```

## Example: MCMC (cont. 2) {.t}

```{r amcmc-gelmanplot, fig.cap='Gelman diagnostic for convergence'}
coda::gelman.plot(ans)
```

## Example: MCMC (cont. 3) {.t}

```{r amcmc-plot, fig.cap='Posterior distribution'}
oldpar <- par(no.readonly = TRUE)
# par(mar = c(2.2,2.2,2,2), las=1, xpd=NA)
plot(ans)
par(oldpar)
```

# Bayesian Estimation of the parameters

## Agenda

\tableofcontents[currentsection]

## Putting all together: MCMC of the model {.t}

In this example, using data from PANTHERDB, we will simulate a single function and use the `aphylo_mcmc` function for obtaining parameter estimates

```{r sim-w-panther, echo=TRUE, cache=TRUE}
# Reading the data
path <- system.file("tree.tree", package="aphylo")
tree <- read_panther(path)$tree

# Simulating a function
set.seed(123)
atree <- sim_annotated_tree(
  tree= as_po_tree(tree),
  Pi = .05, mu = c(.1, .05), psi = c(.01, .02)
)

# Estimation
ans <- aphylo_mcmc(
  params  = rep(.05, 5),
  dat     = atree,
  # Passing a Beta prior
  priors  = function(p) dbeta(p, 2, 20),
  # Parameters for the MCMC
  control = list(nchain=4, nbatch=1e4, thin=20, burnin=1e3)
  )
```



## Putting all together: MCMC of the model (cont. 1) {.t}

```{r panther-output, echo=TRUE}
ans
```

## How good is our prediction {.t}

```{r print-pred-score, echo=TRUE}
# Looking at the posterior probabilities
head(predict(ans, what="leafs"))

# And to the prediction score
prediction_score(ans)
```


## How good is our prediction (cont.) {.t}

```{r plot-pred-score, fig.cap="Predicted versus Observed values. Each slice of the pie represents a gene, the outer half of a slice is the predicted value, while the inner half is the observed value. Good predictions will coincide in color and show the slice closer to the center of the plot.", out.width=".6\\linewidth", echo=TRUE}
plot(prediction_score(ans), main="")
```

# Concluding Remarks

## Concluding Remarks

-   A parsimonious model of gene functions: easy to apply on a large scale (we already ran some simulations using all 14,000 trees from the Panther DB).\pause

-   Already implemented, we are currently in the stage of writing the paper and setting up the simulation study.\pause

-   Unfortunately, since annotation data is so sparse, we lack of a significant number of useful datasets on which we can test our method.\pause

-   For the next steps, we are evaluating ways of solving the sparseness issue: either by imposing correlation structures accross functions, or jumping into another model.\pause

