---
title: "Phylogenic Trees"
output:
  html_vignette:
    md_extensions: +latex_macros
keep_tex: true
---

\newcommand{\isone}[1]{{\boldsymbol{1}\left\{ #1 \right\}}}
\renewcommand{\Pr}[1]{{\mbox{Pr}\left\{#1\right\} }}
\newcommand{\Prcond}[2]{{\mbox{Pr}\left\{#1\;|\;#2\right\} }}

## Definitions

A set of $n$ genes $N \equiv \{i \in \{1,\dots,n\}\}$ is partially order accordignly to its relations as parent and offsprings such that for any $i,j \in N$ for which a directed path exists, $i<j$ iff $i$ is a parent node and $j$ a descendant.

Each leaf nodes has $2^p$ different possible states, which are stored in a $N\times 2^P$ array. Each row is filled with a particular combination of $\{0,1\}^P$, e.g. $s = \{0,0,0\}$.

In the experimental data, for each leaf $l$, we have the observed state defined by the vector $z_l\equiv\{z_{lp}\}_{p=1}^P$ with 

$$
z_{lp} = \left\{
\begin{array}{ll}
1 & \mbox{if the function }p\mbox{ is active}\\
0 & \mbox{if the function }p\mbox{ is not active}\\
9 & \mbox{if we don't have information }
\end{array}\right.
$$

This way, given that the true state is $s\equiv\{s_p\}_{p=1}^P$, the probability of classifying leaf $l$ as $s'$ is:

$$ 
\Psi_{ss'} = \Prcond{Z=s'}{S=s} = \left\{
\begin{array}{ll}
\prod_p\{\psi_p^\isone{s_{lp}'=s_{lp}}(1-\psi_p)^\isone{s_{lp}'\neq s_{lp}}\} & \mbox{if }s_{lp}'\neq 9 \\
1 & \mbox{otherwise}
\end{array}
\right.
$$ 
Where $\psi\equiv\left\{ \psi_p \right\}_{p=1}^P$ are misclassification probabilities.

For internal node $i$, instead of misclassification probabilities, we define the likelihood using gain and loss functions (also stored as a $N\times 2^P$ array). Furthermore, it is defined conditionally on $i$'s offsprings $o_i\subset\{j\in N:j<i\}$, which has cardinality $|o_i|=O_i$, and the true state $s$. Let $x_i\equiv\{x_{ip}\}_{p=1}^P$ denote the vector of functional states of $i$, then, the probability that we observe $X=x_i$ conditional on the true state of its offsprings $j\in o_i$ is:

 
$$
\Pr{\mu, \psi}_{n,s}  = \prod_{o_n} \sum_{s_n'} \Psi_{s_n's'}
\prod_p \left(\left[\underbrace{\mu_0^\isone{s_{np}'}}_{\mbox{Gain}}\underbrace{(1-\mu_0)^\isone{\neg s_{np}'}}_{\mbox{No gain}}\right]^\isone{\neg s_p}\times
  \left[\underbrace{\mu_1^\isone{\neg s_{np}'}}_{\mbox{Loss}}\underbrace{(1-\mu_1)^\isone{s_{np}'}}_{\mbox{No Loss}}\right]^\isone{s_p}\right)
$$

Computationally, observe that the larger parenthesis can be computed only once and then retrieved depending on the values of $\{s_{np}',s_p\}$. Let $M\equiv\{m_{s_n,s}\}$ to be an array of size $2\times 2$ holding the Gain/Loss probabilities, then, the previous equation reduces to:

$$
\Pr{\mu, \psi}_{n,s}  = \prod_{o_n} \sum_{s_n'} \Psi_{s_n's'}
\prod_p m_{s_{np}', s}
$$

Finally, define $\pi\equiv\{\pi_0,\pi_1\}$ to be the root node state probabilities, then, the likelihood function can be computed as

$$
L(\pi,\mu,\Psi) = \sum_s \pi_s \Pr{\mu, \psi}_{n,s}
$$